{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic comment classification Keras",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitishast/TF/blob/master/Toxic_comment_classification_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u59aW9K-QDt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "#python 3.6\n",
        "#anaconda 5.1.0 windows-x86 64 exe\n",
        "#tensorflow==1.12.0\n",
        "#Keras==2.2.4\n",
        "#https://www.kaggle.com/sbongo/for-beginners-tackling-toxic-using-keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ev-FoSMQLMt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"train_preprocessed.csv\")\n",
        "test = pd.read_csv(\"test_preprocessed.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-WUQMUYQtof",
        "colab_type": "code",
        "outputId": "15f0a2fc-68ee-4e37-aaad-0ecabf8cdcd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "test.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>comment_text</th>\n",
              "      <th>id</th>\n",
              "      <th>identity_hate</th>\n",
              "      <th>insult</th>\n",
              "      <th>obscene</th>\n",
              "      <th>set</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>threat</th>\n",
              "      <th>toxic</th>\n",
              "      <th>toxicity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>yo bitch ja rule is more succesful then you ll...</td>\n",
              "      <td>00001cee341fdb12</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>from rfc the title is fine as it is  imo</td>\n",
              "      <td>0000247867823ef7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>test</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        comment_text                id  \\\n",
              "0  yo bitch ja rule is more succesful then you ll...  00001cee341fdb12   \n",
              "1          from rfc the title is fine as it is  imo   0000247867823ef7   \n",
              "\n",
              "   identity_hate  insult  obscene   set  severe_toxic  threat  toxic  toxicity  \n",
              "0            NaN     NaN      NaN  test           NaN     NaN    NaN       NaN  \n",
              "1            NaN     NaN      NaN  test           NaN     NaN    NaN       NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byMebhrFqM8o",
        "colab_type": "code",
        "outputId": "c754a69f-8fb9-4ebc-c70a-174ccd02b6da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "test.isnull().any(), train.isnull().any()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(comment_text      True\n",
              " id               False\n",
              " identity_hate     True\n",
              " insult            True\n",
              " obscene           True\n",
              " set              False\n",
              " severe_toxic      True\n",
              " threat            True\n",
              " toxic             True\n",
              " toxicity          True\n",
              " dtype: bool, comment_text     False\n",
              " id               False\n",
              " identity_hate    False\n",
              " insult           False\n",
              " obscene          False\n",
              " set              False\n",
              " severe_toxic     False\n",
              " threat           False\n",
              " toxic            False\n",
              " toxicity         False\n",
              " dtype: bool)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKtmuK8eW0tb",
        "colab_type": "text"
      },
      "source": [
        "## checking for null values and filling it with something"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTfGPFYBW-YY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.replace(np.nan, '', regex=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYlKorodqpHX",
        "colab_type": "text"
      },
      "source": [
        "Splitting the train dataset into X & Y with features(imp)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ernnzp9hq0c_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_classes = [\"toxic\",\"severe_toxic\",\"obscene\",\"threat\",\"insult\",\"identity_hate\"]\n",
        "y = train[list_classes].values\n",
        "list_sentences_train= train[\"comment_text\"]\n",
        "list_sentences_test= test[\"comment_text\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiqaiupwyPba",
        "colab_type": "text"
      },
      "source": [
        "Using tokenising forming adictionary of words in the comment and then feeding to the LSTM "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3yK6Yb2szp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features =20000\n",
        "tokenizer = Tokenizer(num_words = max_features)\n",
        "tokenizer.fit_on_texts(list(list_sentences_train))\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
        "list_tokenized_test  = tokenizer.texts_to_sequences(list_sentences_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSDuCOp32Wy7",
        "colab_type": "text"
      },
      "source": [
        "##Checking the dict and indexes of words. Keras does this thing in 4 lines of code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7Hf5E9L12XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#for occurence of words\n",
        "tokenizer.word_counts\n",
        "#for index of words\n",
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiSGTbUbq0Iv",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL4EG8DOqmoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_tokenized_train[:2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdWuKb8U5RTV",
        "colab_type": "text"
      },
      "source": [
        "### we use \"padding\"! We could make the shorter sentences as long as the others by filling the shortfall by zeros.But on the other hand, we also have to trim the longer ones to the same length(maxlen) as the short ones. In this case, we have set the max length to be 200."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfTyaUeOpz3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_length = 200\n",
        "X_t = pad_sequences(list_tokenized_train,maxlen=max_length)\n",
        "X_te= pad_sequences(list_tokenized_test,maxlen=max_length)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljCmFTQD_t-r",
        "colab_type": "text"
      },
      "source": [
        "### Note: How to set the perfect max length for the comments. les lenght looses out on feature and more length increases the cell size of LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "edTvFyUJqnta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "totalnumwords = [len(one_comment) for one_comment in list_tokenized_train]\n",
        "totalnumwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_kdEOupBkwx",
        "colab_type": "text"
      },
      "source": [
        "## categorising the comments lenght in bins and then plotting a histogram to see the distributions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IO1XYYAq_pN7",
        "colab_type": "code",
        "outputId": "10c919a9-1d5e-407b-85b9-2005b7738132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "plt.hist(totalnumwords,bins = np.arange(0,410,10))# creating bins and then plotting the comments length"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([21647., 26776., 21885., 16161., 12809.,  9996.,  7679.,  6073.,\n",
              "         4693.,  3907.,  3280.,  2733.,  2370.,  1939.,  1665.,  1511.,\n",
              "         1323.,  1251.,  1081.,   875.,   778.,   772.,   590.,   567.,\n",
              "          534.,   483.,   442.,   360.,   380.,   279.,   266.,   236.,\n",
              "          222.,   202.,   138.,   155.,   155.,   149.,   140.,   136.]),\n",
              " array([  0,  10,  20,  30,  40,  50,  60,  70,  80,  90, 100, 110, 120,\n",
              "        130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250,\n",
              "        260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380,\n",
              "        390, 400]),\n",
              " <a list of 40 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfalxzAJBzW4",
        "colab_type": "text"
      },
      "source": [
        "# Building the model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5Q9cgpR22I",
        "colab_type": "text"
      },
      "source": [
        "## Beginining by creating an input layer which accepts a list of sentences which has dimensions  200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3iMdU0fBfZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#By indicating an empty space after comma, we are telling Keras to infer the number automatically.\n",
        "inp = Input(shape=(max_length, )) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvTS2Tluts70",
        "colab_type": "text"
      },
      "source": [
        "#### We need to define the size of the \"vector space\" we have mentioned above, and the number of unique words(max_features) we are using. Again, the embedding size is a parameter that you can tune and experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bevniHubt4nc",
        "colab_type": "text"
      },
      "source": [
        "####The output of the Embedding layer is just a list of the coordinates of the words in this vector space. For eg. (-81.012) for \"cat\" and (-80.012) for \"dog\". We could also use the distance of these coordinates to detect relevance and context."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXS85WmDt3wk",
        "colab_type": "code",
        "outputId": "2c612874-b9ee-43f2-b572-72b62ca190d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "embed_size = 128\n",
        "x = Embedding(max_features, embed_size)(inp)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aiy5jfSKxFm0",
        "colab_type": "text"
      },
      "source": [
        "https://medium.com/@quantumsteinke/whats-the-difference-between-a-matrix-and-a-tensor-4505fbdc576c"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtmQl5EKOluv",
        "colab_type": "text"
      },
      "source": [
        "### Next, we feed this Tensor into the LSTM layer. We set the LSTM to produce an output that has a dimension of 60 and want it to return the whole unrolled sequence of results. As you probably know, LSTM or RNN works by recursively feeding the output of a previous network into the input of the current network, and you would take the final output after X number of recursion. But depending on use cases, you might want to take the unrolled, or the outputs of each recursion as the result to pass to the next layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMpZrMM2OtDP",
        "colab_type": "text"
      },
      "source": [
        "LSTM takes in a tensor of [Batch Size, Time Steps, Number of Inputs].\n",
        "\n",
        "\n",
        "1.  **Batch size** is the number of samples in a batch.\n",
        "2.   **time steps** is the number of recursion it runs for each input, or it could be pictured as the number of \"A\"s in the above picture. Lastly,\n",
        "3.  **number of inputs** is the number of variables(number of words in each sentence in our case) you pass into LSTM as pictured in \"x\" above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbGIv-8Vtsns",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = LSTM(60,return_sequences=True,name ='lstm_layer')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYnwkeFu2yfj",
        "colab_type": "text"
      },
      "source": [
        "## Before we could pass the output to a normal layer, we need to reshape the 3D tensor into a 2D one. We reshape carefully to avoid throwing away data that is important to us, and ideally we want the resulting data to be a good representative of the original data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asKVYSEP2rpb",
        "colab_type": "text"
      },
      "source": [
        "### Global Max Pooling layer which is traditionally used in CNN problems to reduce the dimensionality of image data. In simple terms, we go through each patch of data, and we take the maximum values of each patch. These collection of maximum values will be a new set of down-sized data we can use"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h_cd8-LBT8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = GlobalMaxPool1D()(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcaGDiPE3Lo8",
        "colab_type": "text"
      },
      "source": [
        "## Purpose of using DROPOUTS is:\n",
        "### We use dropout which indiscriminaterly disables some nodes so that nodes in the next layer is forces to handle the representation of missing data and the whole network could result in better generalisation \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amhrQlvK3ti_",
        "colab_type": "text"
      },
      "source": [
        "#### dropping 10% of nodes i.e. 01.**bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMDcaRlq3ApE",
        "colab_type": "code",
        "outputId": "e7863ba2-2866-4cc5-ed22-14128b42903d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_coyIp132TQ",
        "colab_type": "text"
      },
      "source": [
        "We pass the output of dropout layer to a dense layer and output passes through a RELU function \n",
        "## Activation((Input * Weights) + Bias )"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptRg0rsL3pMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(50, activation=\"relu\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7jpI6Eh4XMo",
        "colab_type": "text"
      },
      "source": [
        "Passing the output to a dropout layer again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn64quXf4WTA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dropout(0.1)(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oO1sijhw4igI",
        "colab_type": "text"
      },
      "source": [
        "### Finally passing this through a sigmoid funtion because we are trying to get the binary classification[0,1] \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2spRN6g54d94",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Dense(6,activation=\"sigmoid\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7g_45dHC5ErM",
        "colab_type": "text"
      },
      "source": [
        "## Final steps: We are almost done! All is left is to define the inputs, outputs and configure the learning process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifY1TtUB40YZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Model(inputs=inp,outputs=x)\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRXovB3aFoAu",
        "colab_type": "code",
        "outputId": "5e2f2439-0c11-4f56-ee74-24f00695ba24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4Pl57V35hll",
        "colab_type": "code",
        "outputId": "4fbb35a8-2d69-4241-caff-0a36f5f44c83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "## Fitting the model with the train and test data sets. \n",
        "batch_size = 32\n",
        "epochs = 2\n",
        "model.fit(X_t,y,batch_size=batch_size, epochs=epochs,validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "Train on 143613 samples, validate on 15958 samples\n",
            "Epoch 1/2\n",
            "143613/143613 [==============================] - 211s 1ms/step - loss: 0.0784 - acc: 0.9750 - val_loss: 0.0524 - val_acc: 0.9806\n",
            "Epoch 2/2\n",
            "143613/143613 [==============================] - 215s 1ms/step - loss: 0.0486 - acc: 0.9817 - val_loss: 0.0490 - val_acc: 0.9814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe9942adcf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3snNNkGX5hib",
        "colab_type": "code",
        "outputId": "02306e89-57e6-43b6-b1ba-25dcf07194cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 200, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 50)                6450      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 50)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 6)                 306       \n",
            "=================================================================\n",
            "Total params: 2,566,756\n",
            "Trainable params: 2,566,756\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wh3IhhS3TN2R",
        "colab_type": "text"
      },
      "source": [
        "## To checkfor the output of a layer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiOSVMPG5hfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HptjdRqkUYLM",
        "colab_type": "code",
        "outputId": "7c27c4f5-86b0-4fea-8a17-e6f6b8b1c1d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "get_3rd_layer_output = k.function([model.layers[0].input],\n",
        "                                  [model.layers[2].output])\n",
        "layer_output = get_3rd_layer_output([X_t[:1]])[0]\n",
        "layer_output.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ilq3ki5ZUYED",
        "colab_type": "code",
        "outputId": "01d62046-5de7-4458-9607-a114204be375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "layer_output"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.23875104,  0.23650843,  0.3112663 ,  0.34676412,  0.20881711,\n",
              "         0.17066254,  0.11643857,  0.2304166 ,  0.19209792,  0.2614349 ,\n",
              "         0.19999133,  0.24715362,  0.16751418,  0.14775519,  0.30145276,\n",
              "         0.16050819,  0.05825273,  0.23378319,  0.08095463,  0.07447441,\n",
              "         0.33564535,  0.11166231,  0.14661536,  0.11577816,  0.21770659,\n",
              "         0.18335508,  0.03967449,  0.09699484,  0.11953064,  0.17595844,\n",
              "         0.14694695,  0.2698373 ,  0.19930907,  0.20590563,  0.08537367,\n",
              "         0.08944958,  0.14104222,  0.03034097,  0.22312653,  0.22423673,\n",
              "         0.20940095,  0.11245004,  0.23824592,  0.31857327,  0.1066708 ,\n",
              "        -0.01256714,  0.05947236,  0.3252051 ,  0.19234265,  0.3188555 ,\n",
              "         0.1980141 ,  0.3477846 ,  0.0990883 ,  0.19465815,  0.12949577,\n",
              "         0.12626562,  0.21397322,  0.23058526,  0.10364183,  0.12151866,\n",
              "         0.18776198,  0.07451349,  0.24807397,  0.2517806 ,  0.45864856,\n",
              "         0.13077365,  0.1599024 , -0.00476002,  0.21630177,  0.06701359,\n",
              "         0.29303437,  0.14619185,  0.31573227,  0.10823085,  0.27811992,\n",
              "         0.3012966 ,  0.09008541,  0.16341949,  0.48351604,  0.34272385,\n",
              "         0.12581657,  0.15517588,  0.36184096,  0.18506874, -0.0609636 ,\n",
              "         0.10542424,  0.24210861,  0.2672132 ,  0.19801335,  0.26812446,\n",
              "         0.33290115,  0.25607005,  0.2671683 ,  0.1553481 ,  0.26003426,\n",
              "         0.2568549 ,  0.25045055,  0.25508425,  0.06335203,  0.32016858,\n",
              "         0.27338567,  0.35766396,  0.36763743,  0.36635742,  0.12899712,\n",
              "         0.19591366,  0.356778  ,  0.18814819,  0.15192209, -0.06259428,\n",
              "         0.17374419,  0.18278356,  0.22652365,  0.1231705 ,  0.23744972,\n",
              "         0.2854546 ,  0.33157423,  0.3632631 ,  0.40906033, -0.04814482,\n",
              "         0.41311756,  0.07080475,  0.05271233,  0.25329727, -0.0227971 ,\n",
              "         0.17705029,  0.35257614,  0.18786371],\n",
              "       [ 0.14184457,  0.21920252,  0.3337201 ,  0.16866149,  0.20881711,\n",
              "         0.1648427 ,  0.11643857,  0.29847923,  0.19209792,  0.16430403,\n",
              "         0.13156152,  0.3217574 ,  0.18603317,  0.12699036,  0.30145276,\n",
              "         0.17554574,  0.03244769,  0.26494274, -0.04423591,  0.08075082,\n",
              "         0.35518652,  0.04963547,  0.14661536,  0.11577816,  0.29369637,\n",
              "         0.14152306, -0.01397266,  0.1363067 ,  0.11953064,  0.17595844,\n",
              "         0.20024082,  0.33993694,  0.3305861 ,  0.3453397 ,  0.00741753,\n",
              "         0.21466726,  0.14104222,  0.03279711,  0.19746046,  0.1863883 ,\n",
              "         0.16473001,  0.11245004,  0.05105361,  0.27166125,  0.12336887,\n",
              "         0.04410597,  0.07283133,  0.07318135,  0.26060927,  0.3188555 ,\n",
              "         0.08587709,  0.3477846 ,  0.15285806,  0.29861134,  0.12280892,\n",
              "         0.09085921,  0.21397322,  0.1617854 ,  0.10364183,  0.12151866,\n",
              "         0.29471266, -0.0367214 ,  0.18787476,  0.16970327,  0.15675294,\n",
              "         0.13077365,  0.1599024 , -0.03694157,  0.12700956,  0.04070774,\n",
              "         0.2850552 ,  0.13627753,  0.17766409,  0.1530925 ,  0.27811992,\n",
              "         0.3033335 ,  0.09008541,  0.2423857 ,  0.43126884,  0.13746771,\n",
              "         0.1400851 ,  0.15517588,  0.15018722,  0.14209178, -0.08951642,\n",
              "         0.12681055,  0.18601583,  0.12230702,  0.26315624,  0.19096275,\n",
              "         0.13139336,  0.34472752,  0.17430568,  0.1553481 ,  0.06846837,\n",
              "         0.2568549 ,  0.16795117,  0.39854342,  0.22560915,  0.1847596 ,\n",
              "         0.10754881,  0.18159091,  0.4196847 ,  0.25901163,  0.12899712,\n",
              "         0.19591366,  0.20988292,  0.24169089,  0.15192209, -0.03681396,\n",
              "         0.17374419,  0.18278356,  0.11779469,  0.17521426,  0.26406088,\n",
              "         0.0611216 ,  0.056645  ,  0.20757005,  0.12673599, -0.07327735,\n",
              "         0.33163616, -0.03949249,  0.05271233,  0.18729274, -0.03241296,\n",
              "         0.15938333,  0.25650942,  0.13128844]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pxexD9SUX7b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7_0KA125hci",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KagZYDme5hZz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCjBVq8X5hW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKqtjXL85hUD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNFdeD7q5hRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7QqQu-r5hN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twk3TFIe5hK4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tM8OUrAi5hHz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}