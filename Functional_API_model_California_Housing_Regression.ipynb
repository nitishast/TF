{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Functional API model California Housing Regression",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPr/2pgHpapoVd4kZHcjk3M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitishast/TF/blob/master/Functional_API_model_California_Housing_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib9vB4-fGdqX",
        "colab_type": "code",
        "outputId": "12fbc3ba-64ba-4db2-ad9e-5e236b5c33f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib as mp\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import scipy\n",
        "from sklearn.datasets import fetch_california_housing\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChoIiDuLGx-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "housing = fetch_california_housing()\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_full,X_test,y_train_full,y_test = train_test_split(housing.data,housing.target)\n",
        "X_train,X_valid,y_train,y_valid = train_test_split(X_train_full,y_train_full)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_valid_scaled = scaler.fit_transform(X_valid)\n",
        "X_test_scaled = scaler.fit_transform(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewxtyPcHG6f2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRJLIOzEHKV3",
        "colab_type": "text"
      },
      "source": [
        "## Two type of networks Multilayer and Wide &  Deep.\n",
        "\n",
        "Lets make a wide and deep model. A wide model connects all or parts of input layer directly to output layer.\n",
        "> It makes the network to learn simple patter using wide(short path) and deep paterns using deep layers(deep path). \n",
        "\n",
        ">A simple MLP passes all the input through stack of layers henc patters can be slighlty distorted or lost in moving from input to output layers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3aBzR_1HH-L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## This is a functional API of Keras. We will call each layer with the output of previous layer.\n",
        "## Once this is has been done, model can be compiled and evaluated.\n",
        "\n",
        "input = keras.layers.Input(shape=X_train.shape[1:])#Defining an input shape. This shape can be different also if we want to train the model on a subset of dat.a\n",
        "#Input layer just accepts the input and not the data actually. \n",
        "hidden1 = keras.layers.Dense(30,activation=\"relu\")(input) # Calling the first dense layer with the input layer as a Function call hence the fuctional API.\n",
        "hidden2 = keras.layers.Dense(30,activation=\"relu\")(hidden1)# Next hidden layer accpets the output of first hidden layer.\n",
        "\n",
        "concat = keras.layers.concatenate([input,hidden2]) # Using this method we can send the input data and output of hidden layer directly to output layer.\n",
        "output = keras.layers.Dense(1)(concat)# Just using one neuron as just need one output value. No activation func as one conti variable. \n",
        "\n",
        "model = keras.models.Model(inputs=[input],outputs=[output]) # Compile this using both input and output layer\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeWBJ4uYEAPB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse',optimizer=\"sgd\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqAkQxzqFGts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKocrAjzFIOj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.fit(X_train_scaled,y_train,epochs=20,validation_data=(X_valid,y_valid))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V-O8ngQFauC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "los = pd.DataFrame(model.history.history)\n",
        "los.plot()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxZlgLxFveN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b70ZkSiTLZi1",
        "colab_type": "text"
      },
      "source": [
        "### By Functional API and input layer, subset can be used for training. \n",
        "Ex: A set of 5 feature from [0,1] and another subset of 6 feature from [2,7]\n",
        "One input is send to Output layer and other input is used to for stacking."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcR3DVC2MN-1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa07603d-d67f-4ca4-fddd-d45cd8e765b6"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11610, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuPjVVnOF5kc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pTcJ4swZ33u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_A = keras.layers.Input(shape=[5])\n",
        "input_B = keras.layers.Input(shape=[6])\n",
        "hidden1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
        "hidden2 = keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
        "concat = keras.layers.concatenate([input_A, hidden2])\n",
        "output = keras.layers.Dense(1)(concat)\n",
        "model1 = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LRFCYZh_Nyfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1.compile(loss='mean_squared_error',optimizer='sgd')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5aZXl7ONf_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "35e61065-cb46-4941-e8e6-9cb20c8a81e3"
      },
      "source": [
        "model1.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 30)           210         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 5)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 30)           930         dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 35)           0           input_3[0][0]                    \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1)            36          concatenate_1[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,176\n",
            "Trainable params: 1,176\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-U7tbBYObDx",
        "colab_type": "text"
      },
      "source": [
        "### While using fit method we should use the two subset as split in layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYj3tuJ_QLfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
        "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
        "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
        "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGTw_8vPPIE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "6b9cdebb-2a9f-4b41-a8d5-b3529645a00c"
      },
      "source": [
        "history = model1.fit((X_train_A,X_train_B),y_train,epochs=20,validation_data=((X_valid_A,X_valid_B),y_valid))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/20\n",
            "11610/11610 [==============================] - 1s 106us/sample - loss: nan - val_loss: nan\n",
            "Epoch 2/20\n",
            "11610/11610 [==============================] - 1s 89us/sample - loss: nan - val_loss: nan\n",
            "Epoch 3/20\n",
            "11610/11610 [==============================] - 1s 89us/sample - loss: nan - val_loss: nan\n",
            "Epoch 4/20\n",
            " 3232/11610 [=======>......................] - ETA: 0s - loss: nan"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-c959af011153>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_valid_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    820\u001b[0m   \"\"\"\n\u001b[1;32m    821\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    940\u001b[0m     \"\"\"\n\u001b[1;32m    941\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZe1bXdzPxmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "los1 = pd.DataFrame(model1.history.history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OASU5S0mXv3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "94439fe6-5794-40ed-c565-6a68ca56cb6a"
      },
      "source": [
        "los1.plot()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8a282eeef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIf4/di+NXRbfymoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_L5MIPKXx1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5fcefe3f-a24c-427f-b338-cc65e58f04e9"
      },
      "source": [
        "model1.evaluate((X_test_A,X_test_B),y_test)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5160/5160 [==============================] - 0s 64us/sample - loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6rEGTTaY3By",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "393a3d3a-1368-48ff-cd1b-d4be911f4e54"
      },
      "source": [
        "model1.predict(X_new_A,X_new_B)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-84f7dbeececc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_A\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_new_B\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, model, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPREDICT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         workers=workers, use_multiprocessing=use_multiprocessing, **kwargs)\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_model_iteration\u001b[0;34m(self, model, mode, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    424\u001b[0m           \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 426\u001b[0;31m           use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    427\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m       \u001b[0muse_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, mode, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m     x, y, sample_weights = standardize(\n\u001b[0;32m--> 646\u001b[0;31m         x, y, sample_weight=sample_weights)\n\u001b[0m\u001b[1;32m    647\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0madapter_cls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mListsOfScalarsDataAdapter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mstandardize_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstandardize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2381\u001b[0m         \u001b[0mis_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2382\u001b[0m         \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2383\u001b[0;31m         batch_size=batch_size)\n\u001b[0m\u001b[1;32m   2384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2385\u001b[0m   def _standardize_tensors(self, x, y, sample_weight, run_eagerly, dict_inputs,\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2408\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2409\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2410\u001b[0;31m           exception_prefix='input')\n\u001b[0m\u001b[1;32m   2411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    537\u001b[0m                        \u001b[0;34m'for inputs '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but instead got the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m                        \u001b[0;34m'following list of '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' arrays: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m                        str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    540\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m       raise ValueError('Error when checking model ' + exception_prefix +\n",
            "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 2 array(s), for inputs ['input_3', 'input_4'] but instead got the following list of 1 arrays: [array([[3.42990000e+00, 2.80000000e+01, 5.03012048e+00, 9.59036145e-01,\n        2.03200000e+03],\n       [4.29440000e+00, 3.70000000e+01, 4.89324619e+00, 1.04793028e+00,\n        9.95000000e+02],\n     ..."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HR6OlHMOZvwa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}